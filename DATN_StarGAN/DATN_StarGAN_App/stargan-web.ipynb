{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":282751991,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r /kaggle/input/stargan-face-ep4/stargan /kaggle/working/\n\n%cd stargan","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:50:12.244481Z","iopub.execute_input":"2025-12-15T06:50:12.244762Z","iopub.status.idle":"2025-12-15T06:50:29.097406Z","shell.execute_reply.started":"2025-12-15T06:50:12.244714Z","shell.execute_reply":"2025-12-15T06:50:29.096417Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/stargan\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%%capture\n!pip install mediapipe rembg onnxruntime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:50:29.099572Z","iopub.execute_input":"2025-12-15T06:50:29.100137Z","iopub.status.idle":"2025-12-15T06:50:56.355407Z","shell.execute_reply.started":"2025-12-15T06:50:29.100105Z","shell.execute_reply":"2025-12-15T06:50:56.354352Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\n\nattr_file_path = '/kaggle/working/stargan/data/celeba/face_attr.txt'\n\n# Xóa tệp nếu tồn tại\nif os.path.exists(attr_file_path):\n    os.remove(attr_file_path)\n    print(f\"Đã xóa tệp {attr_file_path}\")\nelse:\n    print(f\"Tệp {attr_file_path} không tồn tại.\")\n\n# Các tiêu chí yêu cầu\nattributes = [\n    \"Arched_Eyebrows\", \"Attractive\", \"Bags_Under_Eyes\", \"Bald\", \"Bangs\", \"Big_Lips\", \n    \"Big_Nose\", \"Black_Hair\", \"Blond_Hair\", \"Blurry\", \"Brown_Hair\", \"Bushy_Eyebrows\", \n    \"Chubby\", \"Double_Chin\", \"Eyeglasses\", \"Goatee\", \"Gray_Hair\", \"Heavy_Makeup\", \n    \"High_Cheekbones\", \"Male\", \"Mouth_Slightly_Open\", \"Mustache\", \"Narrow_Eyes\", \n    \"No_Beard\", \"Oval_Face\", \"Pale_Skin\", \"Pointy_Nose\", \"Receding_Hairline\", \n    \"Rosy_Cheeks\", \"Sideburns\", \"Smiling\", \"Straight_Hair\", \"Wavy_Hair\", \n    \"Wearing_Earrings\", \"Wearing_Hat\", \"Wearing_Lipstick\", \"Wearing_Necklace\", \n    \"Wearing_Necktie\", \"Young\"\n]\n\npositive_attributes = [\"Black_Hair\", \"Male\", \"Pale_Skin\"]\n\nwith open(attr_file_path, 'w') as f:\n    # Dòng đầu tiên: số ảnh \n    f.write(\"1\\n\")\n    \n    # Dòng thứ hai: các tiêu chí\n    f.write(\"5_o_Clock_Shadow \")\n    f.write(\" \".join(attributes) + \"\\n\")\n    \n    # Dòng thứ 3: chứa thông tin ảnh và giá trị\n    values = [\"1\" if attr in positive_attributes else \"-1\" for attr in attributes]\n    f.write(f\"face_image.jpg \" + \" \".join(values) + \"\\n\")\n\nprint(f\"Đã tạo lại tệp {attr_file_path}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:50:56.356626Z","iopub.execute_input":"2025-12-15T06:50:56.356974Z","iopub.status.idle":"2025-12-15T06:50:56.366779Z","shell.execute_reply.started":"2025-12-15T06:50:56.356943Z","shell.execute_reply":"2025-12-15T06:50:56.365757Z"}},"outputs":[{"name":"stdout","text":"Tệp /kaggle/working/stargan/data/celeba/face_attr.txt không tồn tại.\nĐã tạo lại tệp /kaggle/working/stargan/data/celeba/face_attr.txt.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import cv2\nimport os\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport mediapipe as mp\nfrom PIL import Image\nfrom rembg import remove\nimport torch\nimport torchvision.transforms as T\n\n\n# Load Mediapipe Face Detection cho việc phát hiện khuôn mặt\nmp_face_detection = mp.solutions.face_detection\nmp_drawing = mp.solutions.drawing_utils\n\ndef detect_and_crop(image, expand_ratio=0.3):\n    \"\"\"\n    Phát hiện khuôn mặt bằng Mediapipe và cắt riêng phần khuôn mặt và phần áo từ ảnh đầu vào.\n    Hộp giới hạn khuôn mặt sẽ được mở rộng theo tỷ lệ expand_ratio.\n    \"\"\"\n    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:\n        # Chuyển đổi ảnh sang RGB vì Mediapipe yêu cầu đầu vào RGB\n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        results = face_detection.process(image_rgb)\n\n        if results.detections:\n            for detection in results.detections:\n                # Lấy tọa độ hộp giới hạn của khuôn mặt\n                bboxC = detection.location_data.relative_bounding_box\n                h, w, _ = image.shape\n                x_min = int(bboxC.xmin * w)\n                y_min = int(bboxC.ymin * h)\n                width = int(bboxC.width * w)\n                height = int(bboxC.height * h)\n\n                # Mở rộng hộp giới hạn khuôn mặt\n                x_min_exp = max(0, x_min - int(width * expand_ratio))\n                y_min_exp = max(0, y_min - int(height * expand_ratio))\n                x_max_exp = min(w, x_min + width + int(width * expand_ratio))\n                y_max_exp = min(h, y_min + height + int(height * expand_ratio))\n\n                # Cắt vùng khuôn mặt mở rộng\n                face_img = image[y_min_exp:y_max_exp, x_min_exp:x_max_exp]\n\n                # Trả về tọa độ và ảnh cắt\n                face_coords = (x_min_exp, y_min_exp, x_max_exp, y_max_exp)\n\n                return face_img, face_coords\n\n    return None, None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:50:56.367823Z","iopub.execute_input":"2025-12-15T06:50:56.368227Z","iopub.status.idle":"2025-12-15T06:52:21.702989Z","shell.execute_reply.started":"2025-12-15T06:50:56.368195Z","shell.execute_reply":"2025-12-15T06:52:21.701803Z"}},"outputs":[{"name":"stderr","text":"2025-12-15 06:50:58.827607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765781459.122773      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765781459.200819      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Hàm cắt ảnh thành từng phần\ndef split_image(image, num_parts=18, part_size=(156, 156)):\n    height, width = image.shape[0], image.shape[1]\n    parts = []\n    for i in range(num_parts):\n        x = (i % num_parts) * part_size[0]\n        y = (i // num_parts) * part_size[1]\n        part = image[y:y + part_size[1], x:x + part_size[0]]\n        parts.append(part)\n    return parts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:52:21.703874Z","iopub.execute_input":"2025-12-15T06:52:21.704424Z","iopub.status.idle":"2025-12-15T06:52:21.710591Z","shell.execute_reply.started":"2025-12-15T06:52:21.704402Z","shell.execute_reply":"2025-12-15T06:52:21.709365Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def face_gan_model():\n    # khuôn mặt\n    !python /kaggle/working/stargan/main.py --mode test --dataset CelebA --image_size 156 --c_dim 17 \\\n                     --selected_attrs Bald Bangs Black_Hair Blond_Hair Chubby Eyeglasses Goatee Gray_Hair Heavy_Makeup Male Mouth_Slightly_Open Mustache No_Beard Pale_Skin Rosy_Cheeks Smiling Wearing_Lipstick \\\n                     --model_save_dir='/kaggle/working/stargan/stargan_celeba/models' \\\n                     --result_dir='/kaggle/working/stargan/stargan_celeba/results'  \\\n                     --attr_path='/kaggle/working/stargan/data/celeba/face_attr.txt'  \\\n                     --celeba_image_dir='/kaggle/working/stargan/data/celeba/img/'  \\\n                     --test_iters='550000'\n    \n    \n    # Đường dẫn đến ảnh\n    image_path = '/kaggle/working/stargan/stargan_celeba/results/1-images.jpg'\n\n    # Đọc ảnh\n    image = cv2.imread(image_path)\n\n    # Cắt ảnh thành 18 phần\n    image_parts = split_image(image, num_parts=18)\n\n    generated_images = image_parts[0:]  # Ảnh sinh ra\n\n    return generated_images","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:52:21.711726Z","iopub.execute_input":"2025-12-15T06:52:21.712039Z","iopub.status.idle":"2025-12-15T06:52:21.739999Z","shell.execute_reply.started":"2025-12-15T06:52:21.712009Z","shell.execute_reply":"2025-12-15T06:52:21.738955Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"%%capture\n!pip install opencv-python opencv-python-headless","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:52:21.743104Z","iopub.execute_input":"2025-12-15T06:52:21.743489Z","iopub.status.idle":"2025-12-15T06:52:30.883653Z","shell.execute_reply.started":"2025-12-15T06:52:21.743444Z","shell.execute_reply":"2025-12-15T06:52:30.882500Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def remove_background(image):\n    \"\"\"Xóa nền trắng của ảnh\"\"\"\n    # Chuyển ảnh sang không gian màu HSV\n    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n    # Định nghĩa khoảng màu trắng trong không gian màu HSV\n    lower_white = np.array([0, 0, 200])\n    upper_white = np.array([255, 255, 255])\n\n    # Tạo mặt nạ cho các pixel trắng\n    mask = cv2.inRange(hsv, lower_white, upper_white)\n\n    # Tạo ảnh kết quả với nền trong suốt\n    result = image.copy()\n\n    # Chuyển đổi ảnh sang BGRA (4 kênh) để có thể sử dụng alpha channel (nền trong suốt)\n    result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n\n    # Gán alpha channel cho các pixel trắng là 0 (trong suốt)\n    result[:, :, 3] = np.where(mask == 255, 0, 255)\n\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:52:30.884853Z","iopub.execute_input":"2025-12-15T06:52:30.885125Z","iopub.status.idle":"2025-12-15T06:52:30.892384Z","shell.execute_reply.started":"2025-12-15T06:52:30.885098Z","shell.execute_reply":"2025-12-15T06:52:30.891244Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def find_face_coordinates(original_image, cropped_image):\n    # Chuyển ảnh sang dạng grayscale\n    gray_original = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n    gray_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n\n    # Sử dụng ORB để phát hiện các điểm đặc trưng\n    orb = cv2.ORB_create()\n    kp1, des1 = orb.detectAndCompute(gray_original, None)\n    kp2, des2 = orb.detectAndCompute(gray_cropped, None)\n\n    # Khớp các điểm đặc trưng giữa ảnh gốc và ảnh cắt\n    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n    matches = bf.match(des1, des2)\n\n    # Sắp xếp các match theo khoảng cách\n    matches = sorted(matches, key=lambda x: x.distance)\n\n    # Lấy tọa độ các điểm đã khớp\n    points_original = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n    points_cropped = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n\n    # Tính toán ma trận phép biến đổi (Homography) giữa ảnh gốc và ảnh cắt\n    matrix, mask = cv2.findHomography(points_cropped, points_original, cv2.RANSAC, 5.0)\n\n    # Tìm ra tọa độ của ảnh cắt trong ảnh gốc\n    h, w = cropped_image.shape[:2]\n    corners_cropped = np.float32([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]]).reshape(-1, 1, 2)\n    corners_original = cv2.perspectiveTransform(corners_cropped, matrix)\n\n    # Lấy tọa độ góc trái trên và góc phải dưới của phần cắt trong ảnh gốc\n    x1, y1 = np.int32(corners_original[0][0])  # Tọa độ góc trái trên (đảm bảo là int)\n    x2, y2 = np.int32(corners_original[2][0])  # Tọa độ góc phải dưới (đảm bảo là int)\n\n    # Kiểm tra xem tọa độ có hợp lệ không\n    if x1 < 0: x1 = 0\n    if y1 < 0: y1 = 0\n    if x2 >= original_image.shape[1]: x2 = original_image.shape[1] - 1\n    if y2 >= original_image.shape[0]: y2 = original_image.shape[0] - 1\n\n    return (x1, y1), (x2, y2)\n\ndef overlay_face_on_original(original_image, cropped_image, face_coords):\n    # Lấy tọa độ góc trái trên và góc phải dưới của phần cắt trong ảnh gốc\n    (x1, y1), (x2, y2) = face_coords\n\n    # Resize ảnh cắt sao cho nó vừa với vùng cần ghép trong ảnh gốc\n    target_width = x2 - x1\n    target_height = y2 - y1\n    resized_cropped_image = cv2.resize(cropped_image, (target_width, target_height))\n\n    # Ghi đè ảnh cắt lên ảnh gốc\n    original_image_with_overlay = original_image.copy()\n    original_image_with_overlay[y1:y1 + resized_cropped_image.shape[0], x1:x1 + resized_cropped_image.shape[1]] = resized_cropped_image\n\n    return original_image_with_overlay\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:52:30.893418Z","iopub.execute_input":"2025-12-15T06:52:30.893779Z","iopub.status.idle":"2025-12-15T06:52:30.924370Z","shell.execute_reply.started":"2025-12-15T06:52:30.893734Z","shell.execute_reply":"2025-12-15T06:52:30.923355Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Hàm gen_img giả định (xử lý ảnh)\ndef gen_img(image_path):\n    # Đọc ảnh bằng OpenCV\n    input_image = cv2.imread(image_path)\n\n    # Phát hiện và cắt khuôn mặt và quần áo từ ảnh đầu vào\n    expand_ratio=0.5\n    face_image, face_coords = detect_and_crop(input_image, expand_ratio)\n\n    if face_image is not None:\n\n        # Lưu ảnh khuôn mặt và quần áo vào các thư mục tương ứng\n        face_save_path = '/kaggle/working/stargan/data/celeba/img/face_image.jpg'\n\n        # Kiểm tra và tạo thư mục nếu chưa tồn tại\n        os.makedirs(os.path.dirname(face_save_path), exist_ok=True)\n        \n        # Hiển thị kết quả đã cắt\n        plt.figure(figsize=(10, 3))\n\n        plt.subplot(1, 3, 1)\n        plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n        plt.title(\"Ảnh gốc\")\n\n        plt.subplot(1, 3, 2)\n        plt.imshow(cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB))\n        plt.title(\"Khuôn mặt đã cắt\")\n\n        face_image = cv2.resize(face_image, (178, 218))\n\n        plt.subplot(1, 3, 3)\n        plt.imshow(cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB))\n        plt.title(\"Khuôn mặt resize\")\n        \n        plt.show()\n\n        # Lưu ảnh\n        cv2.imwrite(face_save_path, face_image)        \n\n        face_result = face_gan_model()\n\n        for i in range(len(face_result)):\n            try:\n                img = Image.fromarray(face_result[i])\n                \n                resized_img = img.resize((720, 720))\n                \n                face_result[i] = np.array(resized_img)\n            except Exception as e:\n                print(f\"Không thể resize ảnh thứ {i}: {e}\")\n\n        #################\n        ### tạo lại ảnh với nền của ảnh cũ \n        input_image = remove_background(input_image)\n        for i in range(len(face_result)):\n            face_result[i] = remove_background(face_result[i])\n    \n        face_coords = find_face_coordinates(input_image, face_result[0])\n\n        for i in range(len(face_result)):\n            face_result[i] = overlay_face_on_original(input_image, face_result[i], face_coords)\n\n        for i in range(len(face_result)):\n            face_result[i] = remove_background(face_result[i])\n        \n        print(\"Đã tạo ảnh.\\n\\n\\n\")\n    else:\n        print(\"Không phát hiện được khuôn mặt hoặc quần áo trong ảnh.\")\n    \n    return face_result[1:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:52:30.925568Z","iopub.execute_input":"2025-12-15T06:52:30.926043Z","iopub.status.idle":"2025-12-15T06:52:30.955361Z","shell.execute_reply.started":"2025-12-15T06:52:30.926018Z","shell.execute_reply":"2025-12-15T06:52:30.954084Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# 17 tiêu chí\ncriteria_names = [\n    \"Hói Đầu\",               # Bald\n    \"Tóc Mái\",               # Bangs\n    \"Tóc Đen\",               # Black Hair\n    \"Tóc Vàng\",              # Blond Hair\n    \"Mũm Mĩm\",               # Chubby\n    \"Đeo Kính\",              # Eyeglasses\n    \"Râu Dê\",                # Goatee\n    \"Tóc Bạc\",               # Gray Hair\n    \"Trang Điểm Đậm\",        # Heavy Makeup\n    \"Nam Giới\",              # Male\n    \"Miệng Hơi Mở\",          # Mouth Slightly Open\n    \"Râu Mép\",               # Mustache\n    \"Không Râu\",             # No Beard\n    \"Da Nhợt Nhạt\",          # Pale Skin\n    \"Má Hồng\",               # Rosy Cheeks\n    \"Mỉm Cười\",              # Smiling\n    \"Đánh Son\"               # Wearing Lipstick\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:52:30.956756Z","iopub.execute_input":"2025-12-15T06:52:30.957127Z","iopub.status.idle":"2025-12-15T06:52:30.979460Z","shell.execute_reply.started":"2025-12-15T06:52:30.957090Z","shell.execute_reply":"2025-12-15T06:52:30.978256Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## Giao diện Web","metadata":{}},{"cell_type":"code","source":"%%capture\n!pip install gradio==3.41.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T06:52:30.980825Z","iopub.execute_input":"2025-12-15T06:52:30.981434Z","iopub.status.idle":"2025-12-15T06:52:50.901590Z","shell.execute_reply.started":"2025-12-15T06:52:30.981407Z","shell.execute_reply":"2025-12-15T06:52:50.900310Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"import shutil\nimport cv2\nfrom PIL import Image\n\ndef process_web_upload(image_path, selected_attr_idx):\n    if image_path is None:\n        return \"Bạn chưa tải ảnh!\", None\n\n    # 1️⃣ Copy ảnh thật từ Gradio temp → Kaggle working\n    save_path = \"/kaggle/working/user_image.jpg\"\n    shutil.copy(image_path, save_path)\n\n    # 2️⃣ Gọi pipeline gen ảnh (GIỮ NGUYÊN CODE CŨ)\n    result_images = gen_img(save_path)\n\n    if result_images is None or len(result_images) != 17:\n        return \"Lỗi: Không tạo đủ 17 ảnh. Kiểm tra lại vùng cắt mặt!\", None\n\n    # 3️⃣ Chọn ảnh theo tiêu chí\n    selected_img = result_images[selected_attr_idx]\n\n    # 4️⃣ Convert OpenCV → PIL để hiển thị web\n    if selected_img.shape[2] == 4:\n        selected_img = cv2.cvtColor(selected_img, cv2.COLOR_BGRA2RGBA)\n    else:\n        selected_img = cv2.cvtColor(selected_img, cv2.COLOR_BGR2RGB)\n\n    pil_img = Image.fromarray(selected_img)\n\n    return f\"Thuộc tính: {criteria_names[selected_attr_idx]}\", pil_img\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T07:07:42.872707Z","iopub.execute_input":"2025-12-15T07:07:42.873560Z","iopub.status.idle":"2025-12-15T07:07:42.881809Z","shell.execute_reply.started":"2025-12-15T07:07:42.873520Z","shell.execute_reply":"2025-12-15T07:07:42.880824Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"with gr.Blocks() as demo:\n    gr.Markdown(\"<h1 style='text-align:center;'>✨ StarGAN Web App — 17 Thuộc Tính ✨</h1>\")\n\n    with gr.Row():\n\n        # Cột trái — Upload ảnh\n        with gr.Column():\n            input_image = gr.Image(\n                label=\"Ảnh đầu vào\",\n                type=\"filepath\"   # ⭐ BẮT BUỘC\n            )\n\n        # Cột giữa — Chọn thuộc tính\n        with gr.Column():\n            attr_dropdown = gr.Dropdown(\n                label=\"Chọn 1 thuộc tính\",\n                choices=criteria_names,\n                value=criteria_names[0]\n            )\n            process_btn = gr.Button(\"⚡ Tạo ảnh\")\n\n        # Cột phải — Output\n        with gr.Column():\n            output_text = gr.Textbox(label=\"Thông báo\")\n            output_image = gr.Image(label=\"Ảnh sinh ra\")\n\n    process_btn.click(\n        fn=lambda img, attr: process_web_upload(img, criteria_names.index(attr)),\n        inputs=[input_image, attr_dropdown],\n        outputs=[output_text, output_image]\n    )\n\ndemo.launch(share=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-15T07:07:46.703311Z","iopub.execute_input":"2025-12-15T07:07:46.703703Z","iopub.status.idle":"2025-12-15T07:07:49.803994Z","shell.execute_reply.started":"2025-12-15T07:07:46.703676Z","shell.execute_reply":"2025-12-15T07:07:49.803174Z"}},"outputs":[{"name":"stdout","text":"Running on local URL:  http://127.0.0.1:7861\nIMPORTANT: You are using gradio version 3.41.2, however version 4.44.1 is available, please upgrade.\n--------\nRunning on public URL: https://ede7a04085d8af0959.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://ede7a04085d8af0959.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}},{"name":"stderr","text":"INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nW0000 00:00:1765782488.229005     175 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nNumba: Attempted to fork from a non-main thread, the TBB library may be in an invalid state in the child process.\n","output_type":"stream"},{"name":"stdout","text":"Namespace(c_dim=17, c2_dim=8, celeba_crop_size=178, rafd_crop_size=256, image_size=156, g_conv_dim=64, d_conv_dim=64, g_repeat_num=6, d_repeat_num=6, lambda_cls=1, lambda_rec=10, lambda_gp=10, dataset='CelebA', batch_size=16, num_iters=200000, num_iters_decay=100000, g_lr=0.0001, d_lr=0.0001, n_critic=5, beta1=0.5, beta2=0.999, resume_iters=None, selected_attrs=['Bald', 'Bangs', 'Black_Hair', 'Blond_Hair', 'Chubby', 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'No_Beard', 'Pale_Skin', 'Rosy_Cheeks', 'Smiling', 'Wearing_Lipstick'], test_iters=550000, num_workers=1, mode='test', use_tensorboard=True, celeba_image_dir='/kaggle/working/stargan/data/celeba/img/', attr_path='/kaggle/working/stargan/data/celeba/face_attr.txt', rafd_image_dir='data/RaFD/train', log_dir='stargan/logs', model_save_dir='/kaggle/working/stargan/stargan_celeba/models', sample_dir='stargan/samples', result_dir='/kaggle/working/stargan/stargan_celeba/results', log_step=10, sample_step=1000, model_save_step=10000, lr_update_step=1000)\nFinished preprocessing the CelebA dataset...\nGenerator(\n  (main): Sequential(\n    (0): Conv2d(20, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (7): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): ReLU(inplace=True)\n    (9): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (10): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (11): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (12): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (13): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (14): ResidualBlock(\n      (main): Sequential(\n        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (15): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (16): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (17): ReLU(inplace=True)\n    (18): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (19): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (20): ReLU(inplace=True)\n    (21): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n    (22): Tanh()\n  )\n)\nG\nThe number of parameters: 8468160\nDiscriminator(\n  (main): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (1): LeakyReLU(negative_slope=0.01)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (3): LeakyReLU(negative_slope=0.01)\n    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (5): LeakyReLU(negative_slope=0.01)\n    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (7): LeakyReLU(negative_slope=0.01)\n    (8): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (9): LeakyReLU(negative_slope=0.01)\n    (10): Conv2d(1024, 2048, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n    (11): LeakyReLU(negative_slope=0.01)\n  )\n  (conv1): Conv2d(2048, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (conv2): Conv2d(2048, 17, kernel_size=(2, 2), stride=(1, 1), bias=False)\n)\nD\nThe number of parameters: 44860352\n2025-12-15 07:08:14.198065: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1765782494.242820     179 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1765782494.255151     179 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-12-15 07:08:21.987206: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\nLoading the trained models from step 550000...\nSaved real and fake images into /kaggle/working/stargan/stargan_celeba/results/1-images.jpg...\nĐã tạo ảnh.\n\n\n\n","output_type":"stream"}],"execution_count":15}]}